# Ironclaw Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Environment
# =============================================================================
ENVIRONMENT=development  # development, staging, production
DEBUG=true

# =============================================================================
# API Server
# =============================================================================
API_HOST=127.0.0.1
API_PORT=8000
API_RELOAD=true
API_WORKERS=1  # Use 1 for development, 4+ for production
SECRET_KEY=your-secret-key-change-this-in-production
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# =============================================================================
# Database (PostgreSQL)
# =============================================================================
DATABASE_URL=postgresql+asyncpg://ironclaw:ironclaw_password@localhost:5432/ironclaw_db
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20
DATABASE_ECHO=false  # Set to true to see SQL queries

# =============================================================================
# Redis Cache
# =============================================================================
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50
REDIS_CACHE_TTL=3600  # 1 hour default cache TTL

# =============================================================================
# Vector Database (Qdrant)
# =============================================================================
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Leave empty for local development
QDRANT_COLLECTION_CONVERSATIONS=ironclaw_conversations
QDRANT_COLLECTION_KNOWLEDGE=ironclaw_knowledge

# =============================================================================
# AI Providers - Add at least ONE API key
# =============================================================================

# OpenAI (GPT-4, GPT-3.5-turbo)
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...
OPENAI_MODEL_FAST=gpt-3.5-turbo
OPENAI_MODEL_SMART=gpt-4-turbo-preview
OPENAI_MODEL_VISION=gpt-4-vision-preview
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7

# Anthropic (Claude 3)
# Get key: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL_FAST=claude-3-haiku-20240307
ANTHROPIC_MODEL_SMART=claude-3-opus-20240229
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TEMPERATURE=0.7

# Google Gemini
# Get key: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIza...
GOOGLE_MODEL_FAST=gemini-1.5-flash
GOOGLE_MODEL_SMART=gemini-1.5-pro
GOOGLE_MAX_TOKENS=4096
GOOGLE_TEMPERATURE=0.7

# Groq (Ultra-fast inference, FREE tier!)
# Get key: https://console.groq.com/keys
GROQ_API_KEY=gsk_...
GROQ_MODEL_FAST=llama-3.1-8b-instant
GROQ_MODEL_SMART=llama-3.1-70b-versatile
GROQ_MAX_TOKENS=4096
GROQ_TEMPERATURE=0.7

# =============================================================================
# Local AI (Intel NPU)
# =============================================================================
ENABLE_LOCAL_AI=true
LOCAL_MODEL_PATH=models/phi-3-mini-4k-instruct
LOCAL_MODEL_NAME=phi-3-mini
LOCAL_DEVICE=NPU  # NPU, CPU, or GPU
LOCAL_PRECISION=INT8  # FP32, FP16, INT8 (INT8 recommended for 16GB RAM)
LOCAL_MAX_TOKENS=2048
LOCAL_TEMPERATURE=0.7

# =============================================================================
# AI Router Configuration
# =============================================================================
ROUTER_DEFAULT_PROVIDER=groq  # openai, anthropic, google, groq, local
ROUTER_ENABLE_LEARNING=true  # Learn from user feedback
ROUTER_ENABLE_COST_TRACKING=true
ROUTER_MAX_COST_PER_DAY_USD=10.0

# Task-specific routing (optional, router will use defaults if not set)
ROUTER_TASK_CONVERSATION=groq  # Fast, cheap for simple chat
ROUTER_TASK_CODE_GENERATION=openai  # GPT-4 is best for code
ROUTER_TASK_REASONING=anthropic  # Claude excels at reasoning
ROUTER_TASK_VISION=openai  # GPT-4V for vision tasks
ROUTER_TASK_PRIVACY=local  # Use local NPU for sensitive data

# =============================================================================
# Performance & Resource Limits
# =============================================================================
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT_SECONDS=120
MAX_MEMORY_MB=8192  # 8GB limit (16GB total RAM - 8GB for OS)
ENABLE_MEMORY_MONITORING=true
MEMORY_WARNING_THRESHOLD_MB=7168  # Warn at 7GB

# =============================================================================
# Monitoring & Observability
# =============================================================================
ENABLE_PROMETHEUS=true
PROMETHEUS_PORT=9090
ENABLE_TRACING=true
TRACING_ENDPOINT=http://localhost:4318  # OpenTelemetry endpoint
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json  # json or text

# =============================================================================
# Security
# =============================================================================
ENABLE_AUTHENTICATION=true
JWT_SECRET_KEY=your-jwt-secret-change-this
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=1440  # 24 hours
ENABLE_RATE_LIMITING=true
RATE_LIMIT_PER_MINUTE=60

# =============================================================================
# Features - Enable/Disable Modules
# =============================================================================
ENABLE_VISION=true
ENABLE_VOICE=true
ENABLE_AUTOMATION=false  # Disabled by default for safety
ENABLE_SECURITY_SCANNING=false  # Only for authorized testing
ENABLE_PLUGINS=true

# =============================================================================
# Development
# =============================================================================
ENABLE_SWAGGER_UI=true
ENABLE_REDOC=true
ENABLE_CORS=true
